{
	"class": "vulnerability",
	"id": "oval:com.ubuntu.oracular:def:2024530540000000",
	"version": "1",
	"metadata": {
		"title": "CVE-2024-53054 on Ubuntu 24.10 (oracular) - medium",
		"description": "In the Linux kernel, the following vulnerability has been resolved:cgroup/bpf: use a dedicated workqueue for cgroup bpf destructionA hung_task problem shown below was found:INFO: task kworker/0:0:8 blocked for more than 327 seconds.\"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.Workqueue: events cgroup_bpf_releaseCall Trace: <TASK> __schedule+0x5a2/0x2050 ? find_held_lock+0x33/0x100 ? wq_worker_sleeping+0x9e/0xe0 schedule+0x9f/0x180 schedule_preempt_disabled+0x25/0x50 __mutex_lock+0x512/0x740 ? cgroup_bpf_release+0x1e/0x4d0 ? cgroup_bpf_release+0xcf/0x4d0 ? process_scheduled_works+0x161/0x8a0 ? cgroup_bpf_release+0x1e/0x4d0 ? mutex_lock_nested+0x2b/0x40 ? __pfx_delay_tsc+0x10/0x10 mutex_lock_nested+0x2b/0x40 cgroup_bpf_release+0xcf/0x4d0 ? process_scheduled_works+0x161/0x8a0 ? trace_event_raw_event_workqueue_execute_start+0x64/0xd0 ? process_scheduled_works+0x161/0x8a0 process_scheduled_works+0x23a/0x8a0 worker_thread+0x231/0x5b0 ? __pfx_worker_thread+0x10/0x10 kthread+0x14d/0x1c0 ? __pfx_kthread+0x10/0x10 ret_from_fork+0x59/0x70 ? __pfx_kthread+0x10/0x10 ret_from_fork_asm+0x1b/0x30 </TASK>This issue can be reproduced by the following pressuse test:1. A large number of cpuset cgroups are deleted.2. Set cpu on and off repeatly.3. Set watchdog_thresh repeatly.The scripts can be obtained at LINK mentioned above the signature.The reason for this issue is cgroup_mutex and cpu_hotplug_lock areacquired in different tasks, which may lead to deadlock.It can lead to a deadlock through the following steps:1. A large number of cpusets are deleted asynchronously, which puts a   large number of cgroup_bpf_release works into system_wq. The max_active   of system_wq is WQ_DFL_ACTIVE(256). Consequently, all active works are   cgroup_bpf_release works, and many cgroup_bpf_release works will be put   into inactive queue. As illustrated in the diagram, there are 256 (in   the acvtive queue) + n (in the inactive queue) works.2. Setting watchdog_thresh will hold cpu_hotplug_lock.read and put   smp_call_on_cpu work into system_wq. However step 1 has already filled   system_wq, 'sscs.work' is put into inactive queue. 'sscs.work' has   to wait until the works that were put into the inacvtive queue earlier   have executed (n cgroup_bpf_release), so it will be blocked for a while.3. Cpu offline requires cpu_hotplug_lock.write, which is blocked by step 2.4. Cpusets that were deleted at step 1 put cgroup_release works into   cgroup_destroy_wq. They are competing to get cgroup_mutex all the time.   When cgroup_metux is acqured by work at css_killed_work_fn, it will   call cpuset_css_offline, which needs to acqure cpu_hotplug_lock.read.   However, cpuset_css_offline will be blocked for step 3.5. At this moment, there are 256 works in active queue that are   cgroup_bpf_release, they are attempting to acquire cgroup_mutex, and as   a result, all of them are blocked. Consequently, sscs.work can not be   executed. Ultimately, this situation leads to four processes being   blocked, forming a deadlock.system_wq(step1)\t\tWatchDog(step2)\t\t\tcpuoffline(step3)\tcgroup_destroy_wq(step4)...2000+ cgroups deleted asyn256 actives + n inactives\t\t\t\t__lockup_detector_reconfigure\t\t\t\tP(cpu_hotplug_lock.read)\t\t\t\tput sscs.work into system_wq256 + n + 1(sscs.work)sscs.work wait to be executed\t\t\t\twarting sscs.work finish\t\t\t\t\t\t\t\tpercpu_down_write\t\t\t\t\t\t\t\tP(cpu_hotplug_lock.write)\t\t\t\t\t\t\t\t...blocking...\t\t\t\t\t\t\t\t\t\t\tcss_killed_work_fn\t\t\t\t\t\t\t\t\t\t\tP(cgroup_mutex)\t\t\t\t\t\t\t\t\t\t\tcpuset_css_offline\t\t\t\t\t\t\t\t\t\t\tP(cpu_hotplug_lock.read)\t\t\t\t\t\t\t\t\t\t\t...blocking...256 cgroup_bpf_releasemutex_lock(&cgroup_mutex);..blocking...To fix the problem, place cgroup_bpf_release works on a dedicatedworkqueue which can break the loop and solve the problem. System wqs arefor misc things which shouldn't create a large number of concurrent workitems. If something is going to generate >---truncated---",
		"affected": {
			"family": "unix",
			"platform": "Ubuntu 24.10"
		},
		"reference": {
			"source": "CVE",
			"ref_id": "CVE-2024-53054",
			"ref_url": "https://www.cve.org/CVERecord?id=CVE-2024-53054"
		},
		"advisory": {
			"severity": "Medium",
			"rights": "Copyright (C) 2024 Canonical Ltd.",
			"public_date": "2024-11-19 18:15:00 UTC",
			"cve": {
				"text": "CVE-2024-53054",
				"href": "https://ubuntu.com/security/CVE-2024-53054",
				"public": "20241119",
				"cvss_score": "5.5",
				"cvss_vector": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H"
			}
		}
	},
	"notes": {},
	"criteria": {
		"criterias": [
			{
				"operator": "OR",
				"criterions": [
					{
						"test_ref": "oval:com.ubuntu.oracular:tst:201245420000000",
						"comment": "linux package in oracular is affected and needs fixing."
					},
					{
						"test_ref": "oval:com.ubuntu.oracular:tst:201245420000010",
						"comment": "linux-aws package in oracular is affected and needs fixing."
					},
					{
						"test_ref": "oval:com.ubuntu.oracular:tst:201245420000020",
						"comment": "linux-azure package in oracular is affected and needs fixing."
					},
					{
						"test_ref": "oval:com.ubuntu.oracular:tst:201245420000030",
						"comment": "linux-gcp package in oracular is affected and needs fixing."
					},
					{
						"test_ref": "oval:com.ubuntu.oracular:tst:201245420000060",
						"comment": "linux-lowlatency package in oracular is affected and needs fixing."
					},
					{
						"test_ref": "oval:com.ubuntu.oracular:tst:201245420000040",
						"comment": "linux-oracle package in oracular is affected and needs fixing."
					},
					{
						"test_ref": "oval:com.ubuntu.oracular:tst:201245420000050",
						"comment": "linux-raspi package in oracular is affected and needs fixing."
					}
				]
			}
		]
	}
}
